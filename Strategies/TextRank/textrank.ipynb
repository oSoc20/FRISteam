{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Used code: https://towardsdatascience.com/textrank-for-keyword-extraction-by-python-c0bae21bcec0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nl_core_news_sm'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fe7f4ea2a2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOP_WORDS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnl_STOP_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnl_core_news_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nl_core_news_sm'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_STOP_WORDS\n",
    "from spacy.lang.nl.stop_words import STOP_WORDS as nl_STOP_WORDS\n",
    "import en_core_web_sm\n",
    "import nl_core_news_sm\n",
    "import pandas as pd\n",
    "\n",
    "ensp = en_core_web_sm.load()\n",
    "#nlsp = nl_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 10 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "    # LANGUAGE SPECIFIC\n",
    "    def set_stopwords(self, stopwords, langTag):  \n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        if langTag == \"en\":\n",
    "            for word in en_STOP_WORDS.union(set(stopwords)):\n",
    "                lexeme = ensp.vocab[word]\n",
    "                lexeme.is_stop = True\n",
    "        elif langTag == \"nl\":\n",
    "            for word in nl_STOP_WORDS.union(set(stopwords)):\n",
    "                lexeme = nlsp.vocab[word]\n",
    "                lexeme.is_stop = True            \n",
    "    \n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "        \n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        print(vocab)\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "    \n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "        \n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "    \n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "            \n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "        \n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "        \n",
    "        return g_norm\n",
    "\n",
    "    \n",
    "    def get_keywords(self, number=10):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        keyword_list = {}\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "            keyword_list[key] = str(value)\n",
    "            print(i)\n",
    "            print(keyword_list)\n",
    "            if i > number:\n",
    "                return keyword_list\n",
    "\n",
    "        \n",
    "        \n",
    "    def analyze(self, text, langTag,\n",
    "                candidate_pos=['NOUN', 'PROPN'], \n",
    "                window_size=4, lower=False, stopwords=list()\n",
    "                ):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "        \n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords, langTag)\n",
    "        \n",
    "        # Pare text by spaCy\n",
    "        if langTag == \"en\":\n",
    "            doc = ensp(text)\n",
    "        elif langTag == \"nl\":\n",
    "            doc = nlsp(text)\n",
    "        \n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "        \n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "        \n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "        \n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "        \n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "        \n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "        \n",
    "        self.node_weight = node_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_keywords(abstract, langTag):\n",
    "    \"\"\"function textrank_keywords : main function to automatically extract keywords from an abstract with TextRank\n",
    "\n",
    "   Args:\n",
    "       abstract (string): an abstract (or paper) as a string\n",
    "       langTag (string): the language of the words in wordList and the synonyms (e.g. 'eng' for English and 'nld' for Dutch)\n",
    "\n",
    "   Returns:\n",
    "       list: {dictionary of terms with their frequency relative to the total amount of words}\n",
    "   \"\"\"\n",
    "    tr4w = TextRank4Keyword()\n",
    "    tr4w.analyze(abstract, langTag, candidate_pos = ['NOUN', 'PROPN'], window_size=4, lower=False)\n",
    "    return tr4w.get_keywords(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OrderedDict()\n0\n{'English': '3.4074624836815457'}\n1\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483'}\n2\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258'}\n3\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388'}\n4\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692'}\n5\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056'}\n6\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092'}\n7\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624'}\n8\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624', 'Britain': '1.1199397272344234'}\n9\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624', 'Britain': '1.1199397272344234', 'Norman': '1.091628316093646'}\n10\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624', 'Britain': '1.1199397272344234', 'Norman': '1.091628316093646', 'Anglia': '1.0814583333333332'}\n11\n{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624', 'Britain': '1.1199397272344234', 'Norman': '1.091628316093646', 'Anglia': '1.0814583333333332', 'peninsula': '1.0814583333333332'}\n"
    }
   ],
   "source": [
    "text = \"English is a West Germanic language that was first spoken in early medieval England and eventually became a global lingua franca.[4][5] It is named after the Angles, one of the ancient Germanic peoples that migrated to the area of Great Britain that later took their name, England. Both names derive from Anglia, a peninsula on the Baltic Sea. English is most closely related to Frisian and Low Saxon, while its vocabulary has been significantly influenced by other Germanic languages, particularly Old Norse (a North Germanic language), as well as Latin and French.[6][7][8] English has developed over the course of more than 1,400 years. The earliest forms of English, a group of West Germanic (Ingvaeonic) dialects brought to Great Britain by Anglo-Saxon settlers in the 5th century, are collectively called Old English. Middle English began in the late 11th century with the Norman conquest of England; this was a period in which English was influenced by Old French, in particular through its Old Norman dialect.[9][10] Early Modern English began in the late 15th century with the introduction of the printing press to London, the printing of the King James Bible and the start of the Great Vowel Shift.[11]\"\n",
    "output = textrank_keywords(text, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'English': '3.4074624836815457', 'Germanic': '2.6674475821772483', 'Old': '2.0987710829599258', 'Great': '1.899764786812388', 'century': '1.811358335457692', 'England': '1.5969644525207056', 'Saxon': '1.3348661457268092', 'language': '1.2692791744095624', 'Britain': '1.1199397272344234', 'Norman': '1.091628316093646', 'Anglia': '1.0814583333333332', 'peninsula': '1.0814583333333332'}\n"
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutchtext = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = textrank_keywords(dutchtext, \"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594893385061",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}