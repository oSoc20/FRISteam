{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Martel√©e Baudouin (FRISteam)\n",
    "\n",
    "## Usage of API UnpayWall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 2, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a728fc077928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtxt_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\FRISteam_Hackaton\\Datacleaning\\clean testdata\\doi.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mread_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtxt_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'publication_title'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'doi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\FRISteam_Hackaton\\Datacleaning\\clean testdata\\doi.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 2, saw 3\n"
     ]
    }
   ],
   "source": [
    "txt_path = r\"C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\FRISteam_Hackaton\\Datacleaning\\clean testdata\\doi.txt\"\n",
    "\n",
    "read_file = pd.read_csv (txt_path, header = None, sep=\"\\t\")\n",
    "read_file.columns = ['publication_title','doi']\n",
    "read_file.to_csv (r'C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\FRISteam_Hackaton\\Datacleaning\\clean testdata\\doi.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_title</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trust and discourse</td>\n",
       "      <td>https://doi.org/10.1075/daps.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The challenge of measuring hunger through survey</td>\n",
       "      <td>https://doi.org/10.1086/686670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finite difference approximation of hedging qua...</td>\n",
       "      <td>https://doi.org/10.1063/1.4756109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mind-sets of boundaryless careers in the publi...</td>\n",
       "      <td>https://doi.org/10.1177/0091026014528479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assessing indicators of currency crisis in Eth...</td>\n",
       "      <td>https://doi.org/10.1111/1467-8268.12149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   publication_title  \\\n",
       "0                                Trust and discourse   \n",
       "1   The challenge of measuring hunger through survey   \n",
       "2  Finite difference approximation of hedging qua...   \n",
       "3  Mind-sets of boundaryless careers in the publi...   \n",
       "4  Assessing indicators of currency crisis in Eth...   \n",
       "\n",
       "                                        doi  \n",
       "0           https://doi.org/10.1075/daps.57  \n",
       "1            https://doi.org/10.1086/686670  \n",
       "2         https://doi.org/10.1063/1.4756109  \n",
       "3  https://doi.org/10.1177/0091026014528479  \n",
       "4   https://doi.org/10.1111/1467-8268.12149  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "\n",
    "excel_path = r\"C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\doi_cleaned.xlsx\"\n",
    "\n",
    "dois_csv = pd.read_excel(excel_path,sep='\\t')\n",
    "dois_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the api of UnpayWall, we have to extract the doi from the doi url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  https://doi.org/10.1075/daps.57\n",
      "1                   https://doi.org/10.1086/686670\n",
      "2                https://doi.org/10.1063/1.4756109\n",
      "3         https://doi.org/10.1177/0091026014528479\n",
      "4          https://doi.org/10.1111/1467-8268.12149\n",
      "                          ...                     \n",
      "95      https://doi.org/10.1177/000348941112000910\n",
      "96    https://doi.org/10.1007/978-94-007-5034-0_19\n",
      "97     https://doi.org/10.1109/nssmic.2009.5401813\n",
      "98     https://doi.org/10.1007/978-94-007-5104-0_8\n",
      "99     https://doi.org/10.1007/978-1-61779-591-6_6\n",
      "Name: doi, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Visualising dois urls\n",
    "dois_urls = dois_csv['doi']\n",
    "print(dois_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1075/daps.57', '10.1086/686670', '10.1063/1.4756109', '10.1177/0091026014528479', '10.1111/1467-8268.12149', '10.1145/2818362', '10.1177/1367549414557803', '10.1111/1467-8500.12207', '10.1177/1464884916657520', '10.1177/0117196815606852', '10.1080/00343404.2014.932906', '10.1088/2053-1583/3/1/015012', '10.1159/000446243', '10.1063/1.4930049', '10.1177/0974927615586932', '10.1177/0142723716639502', '10.1007/978-3-319-48393-1_29', '10.1183/13993003.00382-2016', '10.1080/00927872.2014.967354', '10.1183/13993003.02049-2016', '10.1111/1365-2664.12644', '10.1007/978-3-319-16009-2_6', '10.1117/12.770725', '10.1080/00319100701790069', '10.1177/0268580916662384', '10.1080/00319100802239479', '10.1117/12.769424', '10.1186/1471-2105-11-361', '10.1080/03088831003700553', '10.1063/1.3295551', '10.1080/02664760902914425', '10.1063/1.3115408', '10.1145/1527286.1527290', '10.1111/idj.12221', '10.7202/1038325ar', '10.1017/s1431927616012484', '10.1016/j.physc.2010.02.037', '10.5334/jbr-btr.955', '10.1063/1.3446892', '10.1063/1.3197635', '10.1080/02664763.2010.515303', '10.1080/19439341003786729', '10.1063/1.3295453', '10.1063/1.3295432', '10.1080/03081060.2010.527184', '10.1007/978-3-642-02843-4_15', '10.1080/13691457.2010.516621', '10.1080/13691457.2010.520411', '10.1007/978-3-642-21058-8', '10.1117/12.877851', '10.1108/01437721111136741', '10.1007/s10910-010-9741-z', '10.1080/19440049.2011.584070', '10.1080/13504622.2011.557499', '10.1063/1.3498060', '10.1063/1.3644158', '10.1080/16184742.2011.624112', '10.1063/1.3507130', '10.1080/17461391003770509', '10.1080/00397709.2011.552848', '10.1063/1.3295405', '10.1145/1559795.1559812', '10.1145/2448496.2448517', '10.1145/2639490.2639507', '10.1145/1989284.1989296', '10.1109/ipcc.2010.5530022', '10.1109/aict.2008.47', '10.1145/2645710.2645732', '10.1109/icde.2008.4497461', '10.1145/1938551.1938560', '10.1145/1804669.1804695', '10.1145/2745754.2745772', '10.1145/2594538.2594552', '10.1145/2213556.2213593', '10.1145/1376916.1376950', '10.1145/2623330.2623334', '10.1145/1807085.1807110', '10.1109/icde.2009.209', '10.1080/03088839.2012.729701', '10.1186/1750-9378-8-40', '10.1185/03007995.2013.837817', '10.1517/14728222.2013.818136', '10.1007/s11356-013-2109-9', '10.1517/14728222.2014.936384', '10.1177/1470357214533448', '10.1517/14712598.2014.902927', '10.1177/1750698016670783', '10.1177/0959354316638764', '10.1108/02651330810904044', '10.1177/0959683609345080', '10.1183/09031936.00035310', '10.1183/09031936.00026711', '10.1080/02602938.2011.581860', '10.1517/13543776.2011.587804', '10.1097/inf.0b013e318173966f', '10.1177/000348941112000910', '10.1007/978-94-007-5034-0_19', '10.1109/nssmic.2009.5401813', '10.1007/978-94-007-5104-0_8', '10.1007/978-1-61779-591-6_6']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_doi(dois_urls_series):\n",
    "    \"\"\"\n",
    "    Extract dois from the dois urls and store them in a list\n",
    "    \"\"\"\n",
    "    slashparts = dois_urls_series.str.split('https://doi.org/')\n",
    "    dois_list = list()\n",
    "    for i in range(len(dois_urls)):\n",
    "        dois_list.append(slashparts[i][1])\n",
    "    return dois_list\n",
    "\n",
    "\n",
    "dois_list = extract_doi(dois_urls)\n",
    "print(dois_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each doi, we extract the DOI object and store it in a directory (json object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1 of 100 articles\n",
      "Done: 2 of 100 articles\n",
      "Done: 3 of 100 articles\n",
      "Done: 4 of 100 articles\n",
      "Done: 5 of 100 articles\n",
      "Done: 6 of 100 articles\n",
      "Done: 7 of 100 articles\n",
      "Done: 8 of 100 articles\n",
      "Done: 9 of 100 articles\n",
      "Done: 10 of 100 articles\n",
      "Done: 11 of 100 articles\n",
      "Done: 12 of 100 articles\n",
      "Done: 13 of 100 articles\n",
      "Done: 14 of 100 articles\n",
      "Done: 15 of 100 articles\n",
      "Done: 16 of 100 articles\n",
      "Done: 17 of 100 articles\n",
      "Done: 18 of 100 articles\n",
      "Done: 19 of 100 articles\n",
      "Done: 20 of 100 articles\n",
      "Done: 21 of 100 articles\n",
      "Done: 22 of 100 articles\n",
      "Done: 23 of 100 articles\n",
      "Done: 24 of 100 articles\n",
      "Done: 25 of 100 articles\n",
      "Done: 26 of 100 articles\n",
      "Done: 27 of 100 articles\n",
      "Done: 28 of 100 articles\n",
      "Done: 29 of 100 articles\n",
      "Done: 30 of 100 articles\n",
      "Done: 31 of 100 articles\n",
      "Done: 32 of 100 articles\n",
      "Done: 33 of 100 articles\n",
      "Done: 34 of 100 articles\n",
      "Done: 35 of 100 articles\n",
      "Done: 36 of 100 articles\n",
      "Done: 37 of 100 articles\n",
      "Done: 38 of 100 articles\n",
      "Done: 39 of 100 articles\n",
      "Done: 40 of 100 articles\n",
      "Done: 41 of 100 articles\n",
      "Done: 42 of 100 articles\n",
      "Done: 43 of 100 articles\n",
      "Done: 44 of 100 articles\n",
      "Done: 45 of 100 articles\n",
      "Done: 46 of 100 articles\n",
      "Done: 47 of 100 articles\n",
      "Done: 48 of 100 articles\n",
      "Done: 49 of 100 articles\n",
      "Done: 50 of 100 articles\n",
      "Done: 51 of 100 articles\n",
      "Done: 52 of 100 articles\n",
      "Done: 53 of 100 articles\n",
      "Done: 54 of 100 articles\n",
      "Done: 55 of 100 articles\n",
      "Done: 56 of 100 articles\n",
      "Done: 57 of 100 articles\n",
      "Done: 58 of 100 articles\n",
      "Done: 59 of 100 articles\n",
      "Done: 60 of 100 articles\n",
      "Done: 61 of 100 articles\n",
      "Done: 62 of 100 articles\n",
      "Done: 63 of 100 articles\n",
      "Done: 64 of 100 articles\n",
      "Done: 65 of 100 articles\n",
      "Done: 66 of 100 articles\n",
      "Done: 67 of 100 articles\n",
      "Done: 68 of 100 articles\n",
      "Done: 69 of 100 articles\n",
      "Done: 70 of 100 articles\n",
      "Done: 71 of 100 articles\n",
      "Done: 72 of 100 articles\n",
      "Done: 73 of 100 articles\n",
      "Done: 74 of 100 articles\n",
      "Done: 75 of 100 articles\n",
      "Done: 76 of 100 articles\n",
      "Done: 77 of 100 articles\n",
      "Done: 78 of 100 articles\n",
      "Done: 79 of 100 articles\n",
      "Done: 80 of 100 articles\n",
      "Done: 81 of 100 articles\n",
      "Done: 82 of 100 articles\n",
      "Done: 83 of 100 articles\n",
      "Done: 84 of 100 articles\n",
      "Done: 85 of 100 articles\n",
      "Done: 86 of 100 articles\n",
      "Done: 87 of 100 articles\n",
      "Done: 88 of 100 articles\n",
      "Done: 89 of 100 articles\n",
      "Done: 90 of 100 articles\n",
      "Done: 91 of 100 articles\n",
      "Done: 92 of 100 articles\n",
      "Done: 93 of 100 articles\n",
      "Done: 94 of 100 articles\n",
      "Done: 95 of 100 articles\n",
      "Done: 96 of 100 articles\n",
      "Done: 97 of 100 articles\n",
      "Done: 98 of 100 articles\n",
      "Done: 99 of 100 articles\n",
      "Done: 100 of 100 articles\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_publication(doi, file_to_save_to):\n",
    "    url = f'http://api.unpaywall.org/v2/{doi}?email=baudlemartino@hotmail.com'\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        if r.status_code == 200:\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                file_to_save_to.write(chunk)\n",
    "    \n",
    "\n",
    "\n",
    "path = r'C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\Publications\\dois'\n",
    "count = 0\n",
    "for doi in dois_list:\n",
    "    doiID = doi.replace('/','_')\n",
    "    if not os.path.exists('{}/{}.json'.format(path,doiID)):\n",
    "        path = path.replace('\\\\','/')\n",
    "        with open('{}/DOI{}.json'.format(path,doiID), 'wb') as file :\n",
    "            get_publication(doi, file)\n",
    "        count += 1\n",
    "        print(f\"Done: {count} of {len(dois_list)} articles\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    publication_title  \\\n",
      "0                                 Trust and discourse   \n",
      "1    The challenge of measuring hunger through survey   \n",
      "2   Finite difference approximation of hedging qua...   \n",
      "3   Mind-sets of boundaryless careers in the publi...   \n",
      "4   Assessing indicators of currency crisis in Eth...   \n",
      "..                                                ...   \n",
      "95                         Commentary on Otosclerosis   \n",
      "96  Tracers for biogenic secondary organic aerosol...   \n",
      "97  Impact of fully 4D reconstruction on kinetic p...   \n",
      "98               Hot recycling of bituminous mixtures   \n",
      "99           DNA barcoding of amphibians and reptiles   \n",
      "\n",
      "                                             doi data received from unpaywall  \\\n",
      "0                https://doi.org/10.1075/daps.57                          yes   \n",
      "1                 https://doi.org/10.1086/686670                          yes   \n",
      "2              https://doi.org/10.1063/1.4756109                           no   \n",
      "3       https://doi.org/10.1177/0091026014528479                          yes   \n",
      "4        https://doi.org/10.1111/1467-8268.12149                           no   \n",
      "..                                           ...                          ...   \n",
      "95    https://doi.org/10.1177/000348941112000910                          yes   \n",
      "96  https://doi.org/10.1007/978-94-007-5034-0_19                           no   \n",
      "97   https://doi.org/10.1109/nssmic.2009.5401813                           no   \n",
      "98   https://doi.org/10.1007/978-94-007-5104-0_8                          yes   \n",
      "99   https://doi.org/10.1007/978-1-61779-591-6_6                          yes   \n",
      "\n",
      "   no paywall                                            pdf url  \n",
      "0       False                                                     \n",
      "1       False                                                     \n",
      "2       False                                                     \n",
      "3       False                                                     \n",
      "4       False                                                     \n",
      "..        ...                                                ...  \n",
      "95      False                                                     \n",
      "96      False                                                     \n",
      "97      False                                                     \n",
      "98       True  http://www.jbsr.be/articles/10.5334/jbr-btr.95...  \n",
      "99       True  http://www.erudit.org/fr/revues/annuaire/2015-...  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "dois_unpaywall_csv = dois_csv\n",
    "dois_unpaywall_csv[\"data received from unpaywall\"] = \"\"\n",
    "dois_unpaywall_csv[\"no paywall\"] = \"\"\n",
    "dois_unpaywall_csv[\"pdf url\"] = \"\"\n",
    "\n",
    "\n",
    "i = 0\n",
    "for filepath in glob.glob(os.path.join(path,'*.json')):\n",
    "    filepath = filepath.replace('\\\\','/')\n",
    "    with open(filepath, 'r') as file :\n",
    "        try:\n",
    "          jsonfile = json.loads(file.read())\n",
    "          dois_unpaywall_csv[\"data received from unpaywall\"][i] = \"yes\"\n",
    "        except:\n",
    "          dois_unpaywall_csv[\"data received from unpaywall\"][i] = \"no\"\n",
    "       \n",
    "        dois_unpaywall_csv[\"no paywall\"][i] = jsonfile[\"is_oa\"]\n",
    "        \n",
    "        #if dois_unpaywall_csv[\"no paywall\"][i] == True:\n",
    "        dois_unpaywall_csv[\"pdf url\"][i] = jsonfile[\"best_oa_location\"][\"url_for_pdf\"]\n",
    "            \n",
    "        \n",
    "        #print(\"{} : {}\".format(jsonfile[\"doi_url\"],jsonfile[\"is_oa\"]))\n",
    "        i=i+1\n",
    "print(dois_unpaywall_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois_unpaywall_csv.to_csv(r'C:\\Users\\Baudouin\\Documents\\IPL_BLOC_3\\Osoc\\dois_information.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
